{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "id": "9M9pzaT3Y1UE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60be7a71-c47f-4a3a-fbdd-2e0a30ca82eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LHRS-Bot Set Up"
      ],
      "metadata": {
        "id": "pHM9QVNF4ef5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download the repo"
      ],
      "metadata": {
        "id": "rNhNRvN7b4a7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/lhrsbot\")"
      ],
      "metadata": {
        "id": "uKAKw4cHfMlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to sample and download EuroSAT images"
      ],
      "metadata": {
        "id": "5cp0YXgpBxA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# random.seed(1500)\n",
        "\n",
        "# def get_random_images(dataset_folder, sample_size=10):\n",
        "#     result_images = []\n",
        "#     category_size = int(sample_size / len(os.listdir(dataset_folder)))\n",
        "#     if category_size < 1:\n",
        "#         category_size = 1\n",
        "\n",
        "#     for category in os.listdir(dataset_folder):\n",
        "#         category_path = os.path.join(dataset_folder, category)\n",
        "#         if os.path.isdir(category_path):\n",
        "#             images = [os.path.join(category_path, img) for img in os.listdir(category_path) if\n",
        "#                       img.endswith(('.jpg', '.png'))]\n",
        "#             # sample from each category\n",
        "#             sampled_images = random.sample(images, min(len(images), category_size))\n",
        "#             result_images.extend(sampled_images)\n",
        "\n",
        "#     return result_images\n",
        "\n",
        "# def download_images_from_drive(dataset_folder, destination_folder, sample_size=10):\n",
        "#     # Get a list of random image paths\n",
        "\n",
        "#     random_images = get_random_images(dataset_folder, sample_size)\n",
        "\n",
        "#     # Download random images to destination folder\n",
        "#     for image_path in random_images:\n",
        "#         file_name = os.path.basename(image_path)\n",
        "#         category = file_name.split('_')[0]  # Extract category from image name\n",
        "#         category_folder = os.path.join(destination_folder, category)\n",
        "#         if not os.path.exists(category_folder):\n",
        "#             os.makedirs(category_folder)  # Create category folder if it doesn't exist\n",
        "#         destination_file_path = os.path.join(category_folder, file_name)\n",
        "#         source_file_path = os.path.join(dataset_folder, image_path)\n",
        "#         # Copy file from source to destination\n",
        "#         os.system(f'cp \"{source_file_path}\" \"{destination_file_path}\"')\n",
        "\n",
        "# # Replace 'your_source_folder_id' and 'your_destination_folder_id' with the actual folder IDs\n",
        "# source_folder_id = '/content/drive/MyDrive/Datasets/EuroSAT/eurosat/2750'\n",
        "# destination_folder_id = '/content/drive/MyDrive/lhrsbot/eurosat_sample'\n",
        "# sample_size = 2001  # Number of random images to download\n",
        "\n",
        "# download_images_from_drive(source_folder_id, destination_folder_id, sample_size)\n",
        "\n",
        "#look at AID dataset"
      ],
      "metadata": {
        "id": "s50wXBLmJL-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#! git clone https://github.com/NJU-LHRS/LHRS-Bot.git /content/drive/MyDrive/lhrsbot"
      ],
      "metadata": {
        "id": "X1IAVVCaZDqT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "091c21c0-cf42-4695-950d-02e65249628a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path '/content/drive/MyDrive/lhrsbot' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install mmcv==2.1.0 -f https://download.openmmlab.com/mmcv/dist/cu121/torch2.1/index.html\n",
        "! pip install https://www.piwheels.org/simple/ml-collections/ml_collections-0.1.1-py3-none-any.whl#sha256=20b5c600fd8e667eadd30e6da6c24faee7f798e51abc2fe238996c9c4058e120\n",
        "! pip install https://files.pythonhosted.org/packages/53/7c/f3656d1ce3b916ea35f454c6a32b56342168c08baf09a0683df240ca2dce/wandb-0.16.5-py3-none-any.whl\n",
        "! pip install deepspeed\n",
        "! pip install timm==0.9.12\n",
        "! pip install pycocoevalcap\n",
        "! pip install torchmetrics\n",
        "! pip install thop\n",
        "! pip install peft\n",
        "! pip install braceexpand\n",
        "! pip install webdataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hh8zEXGtFkt",
        "outputId": "f5ac21e0-bbd8-4409-fb44-f56fdf9575f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu121/torch2.1/index.html\n",
            "Collecting mmcv==2.1.0\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu121/torch2.1.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (94.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.1/94.1 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmcv==2.1.0)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Collecting mmengine>=0.3.0 (from mmcv==2.1.0)\n",
            "  Downloading mmengine-0.10.3-py3-none-any.whl (451 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv==2.1.0) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv==2.1.0) (24.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv==2.1.0) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv==2.1.0) (6.0.1)\n",
            "Collecting yapf (from mmcv==2.1.0)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv==2.1.0) (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv==2.1.0) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv==2.1.0) (13.7.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv==2.1.0) (2.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==2.1.0) (7.1.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==2.1.0) (4.2.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv==2.1.0) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv==2.1.0) (3.18.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv==2.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv==2.1.0) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv==2.1.0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv==2.1.0) (1.16.0)\n",
            "Installing collected packages: addict, yapf, mmengine, mmcv\n",
            "Successfully installed addict-2.4.0 mmcv-2.1.0 mmengine-0.10.3 yapf-0.40.2\n",
            "Collecting ml-collections==0.1.1\n",
            "  Downloading https://www.piwheels.org/simple/ml-collections/ml_collections-0.1.1-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.5/94.5 kB\u001b[0m \u001b[31m384.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml-collections==0.1.1) (1.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml-collections==0.1.1) (6.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ml-collections==0.1.1) (1.16.0)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from ml-collections==0.1.1) (21.6.0)\n",
            "Installing collected packages: ml-collections\n",
            "Successfully installed ml-collections-0.1.1\n",
            "Collecting wandb==0.16.5\n",
            "  Downloading wandb-0.16.5-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.5) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb==0.16.5)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.5) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.5) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb==0.16.5)\n",
            "  Downloading sentry_sdk-1.45.0-py2.py3-none-any.whl (267 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.1/267.1 kB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb==0.16.5)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.5) (6.0.1)\n",
            "Collecting setproctitle (from wandb==0.16.5)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.5) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.5) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb==0.16.5) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb==0.16.5) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb==0.16.5)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.16.5) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.16.5) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.16.5) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb==0.16.5) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb==0.16.5)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-1.45.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.5\n",
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.14.1.tar.gz (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from deepspeed)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.7.0)\n",
            "Collecting pynvml (from deepspeed)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.66.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->deepspeed) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->deepspeed)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->deepspeed)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->deepspeed)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->deepspeed)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->deepspeed)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->deepspeed)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->deepspeed)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->deepspeed)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->deepspeed)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->deepspeed)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->deepspeed)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->deepspeed)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.14.1-py3-none-any.whl size=1421791 sha256=bf05c78d5edb360d15a74ef88fce6475bd720a34f5893eec39493b246dc43d75\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/fc/2e/6b7f04a0a1c7d002edfcf787965c69b90eee5b3aed189d5ffe\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: ninja, hjson, pynvml, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, deepspeed\n",
            "Successfully installed deepspeed-0.14.1 hjson-3.1.0 ninja-1.11.1.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 pynvml-11.5.0\n",
            "Collecting timm==0.9.12\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm==0.9.12) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm==0.9.12) (0.17.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm==0.9.12) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm==0.9.12) (0.20.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm==0.9.12) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm==0.9.12) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->timm==0.9.12) (12.4.127)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.12) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.12) (4.66.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm==0.9.12) (24.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.9.12) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm==0.9.12) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm==0.9.12) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.12) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.12) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.12) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm==0.9.12) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm==0.9.12) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.12\n",
            "Collecting pycocoevalcap\n",
            "  Downloading pycocoevalcap-1.2-py3-none-any.whl (104.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.3/104.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from pycocoevalcap) (2.0.7)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->pycocoevalcap) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pycocotools>=2.0.2->pycocoevalcap) (1.25.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.16.0)\n",
            "Installing collected packages: pycocoevalcap\n",
            "Successfully installed pycocoevalcap-1.2\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.25.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.2.1+cu121)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.11.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.11.2 torchmetrics-1.3.2\n",
            "Collecting thop\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->thop) (12.4.127)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop) (1.3.0)\n",
            "Installing collected packages: thop\n",
            "Successfully installed thop-0.1.1.post2209072238\n",
            "Collecting peft\n",
            "  Downloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.2)\n",
            "Collecting accelerate>=0.21.0 (from peft)\n",
            "  Downloading accelerate-0.29.3-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.6/297.6 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
            "Installing collected packages: accelerate, peft\n",
            "Successfully installed accelerate-0.29.3 peft-0.10.0\n",
            "Collecting braceexpand\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Installing collected packages: braceexpand\n",
            "Successfully installed braceexpand-0.1.7\n",
            "Collecting webdataset\n",
            "  Downloading webdataset-0.2.86-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: braceexpand in /usr/local/lib/python3.10/dist-packages (from webdataset) (0.1.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from webdataset) (1.25.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from webdataset) (6.0.1)\n",
            "Installing collected packages: webdataset\n",
            "Successfully installed webdataset-0.2.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! huggingface-cli login"
      ],
      "metadata": {
        "id": "aHALnNzdsmAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911a565c-83f6-4eae-c49c-606b9cc57569"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gdown --folder https://drive.google.com/drive/folders/1dzWTE1k935MjMVnfLtTJiIqw7yCj-e3m"
      ],
      "metadata": {
        "id": "ef6-8mvVsmCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1eae951-2bb4-473f-b5fd-f1d3d78a1ef7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 1V-RdYNW3pVsAbwCFTV_5pEGQAjqgLnOG FINAL.pt\n",
            "Retrieving folder 1P40OopWAHWt5hAhnVY7MFQa37K6YCSq2 TextLoRA\n",
            "Processing file 1asZy4jmt1MI8EaQwA3CbJvD9A2zskLUg adapter_config.json\n",
            "Processing file 1VISstMEt6n_qqShRtUrbWbM4_9e9x3da adapter_model.safetensors\n",
            "Processing file 14Iz4mh14GX30ZNzuPSGLWbailXa-UMky README.md\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1V-RdYNW3pVsAbwCFTV_5pEGQAjqgLnOG\n",
            "From (redirected): https://drive.google.com/uc?id=1V-RdYNW3pVsAbwCFTV_5pEGQAjqgLnOG&confirm=t&uuid=b38adb76-68bc-4029-ab38-701ef6c4cca6\n",
            "To: /content/drive/MyDrive/lhrsbot/Stage3/FINAL.pt\n",
            "100% 1.03G/1.03G [00:43<00:00, 23.6MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1asZy4jmt1MI8EaQwA3CbJvD9A2zskLUg\n",
            "To: /content/drive/MyDrive/lhrsbot/Stage3/TextLoRA/adapter_config.json\n",
            "100% 9.09k/9.09k [00:00<00:00, 21.4MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1VISstMEt6n_qqShRtUrbWbM4_9e9x3da\n",
            "From (redirected): https://drive.google.com/uc?id=1VISstMEt6n_qqShRtUrbWbM4_9e9x3da&confirm=t&uuid=50a46053-148c-46b6-84a2-c64302185732\n",
            "To: /content/drive/MyDrive/lhrsbot/Stage3/TextLoRA/adapter_model.safetensors\n",
            "100% 640M/640M [00:07<00:00, 86.0MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=14Iz4mh14GX30ZNzuPSGLWbailXa-UMky\n",
            "To: /content/drive/MyDrive/lhrsbot/Stage3/TextLoRA/README.md\n",
            "100% 105/105 [00:00<00:00, 340kB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to run the model!!!"
      ],
      "metadata": {
        "id": "RjNPsbEXCnup"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AID:"
      ],
      "metadata": {
        "id": "IGPpZODM2A-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_cls.py -c /content/drive/MyDrive/lhrsbot/Config/multi_modal_eval.yaml --model-path /content/drive/MyDrive/lhrsbot/Stage3/FINAL.pt --data-path /content/drive/MyDrive/Datasets/AID_resolution/Size_50/ --accelerator \"gpu\" --workers 4 --enable-amp True --output /content/drive/MyDrive/lhrsbot/output/AID_results/Size_50/ --batch-size 8"
      ],
      "metadata": {
        "id": "8mfF0roRsl91",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "353224ae-5cd8-434a-fe4a-69c23b3c901a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-04-18 22:29:33,591] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
            "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
            "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
            "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
            "\u001b[93m [WARNING] \u001b[0m NVIDIA Inference is only supported on Ampere and newer architectures\n",
            "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.2\n",
            "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.2.0), only 1.0.0 is known to be compatible\n",
            "2024-04-18 22:29:53.201965: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-18 22:29:53.202022: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-18 22:29:53.203466: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-18 22:29:54.524408: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Not using distributed mode.\n",
            "accelerator: gpu\n",
            "adjust_norm: false\n",
            "alignment_dim: 768\n",
            "batch_size: 8\n",
            "bf16: true\n",
            "bits: 16\n",
            "config: null\n",
            "data_path: /content/drive/MyDrive/Datasets/AID_resolution/Size_50/\n",
            "double_quant: true\n",
            "dtype: float16\n",
            "enable_amp: true\n",
            "entity: pumpkinn\n",
            "epochs: 2\n",
            "eval:\n",
            "  dataset: AID\n",
            "fp16: false\n",
            "generate: false\n",
            "gpus: 0\n",
            "inf_sampler: false\n",
            "is_distribute: false\n",
            "local_rank: 0\n",
            "lora:\n",
            "  enable: false\n",
            "  lora_alpha: 256\n",
            "  lora_bias: none\n",
            "  lora_dropout: 0.05\n",
            "  lora_r: 128\n",
            "lr: 0.0002\n",
            "max_grad_norm: 0.3\n",
            "model_path: /content/drive/MyDrive/lhrsbot/Stage3/FINAL.pt\n",
            "optimizer: adanp\n",
            "opts: null\n",
            "output: /content/drive/MyDrive/lhrsbot/output/AID_results/Size_50/\n",
            "project: MaskIndexNet\n",
            "prompt_template: llava_llama_2\n",
            "quant_type: nf4\n",
            "rank: 0\n",
            "rgb_vision:\n",
            "  arch: vit_large\n",
            "  attn_pooler:\n",
            "    num_attn_heads: 16\n",
            "    num_layers: 6\n",
            "    num_query: 144\n",
            "  input_patchnorm: false\n",
            "  input_size:\n",
            "  - 224\n",
            "  - 224\n",
            "  patch_dropout: 0.0\n",
            "  tune_pooler: true\n",
            "  vit_name: openai/clip-vit-large-patch14\n",
            "sar_vision:\n",
            "  activate: sigmoid\n",
            "  alpha: 0.2\n",
            "  arch: base\n",
            "  branch_temp: 0.07\n",
            "  decoder:\n",
            "    heads: 12\n",
            "    hidden_size: 768\n",
            "    layers: 12\n",
            "    mask_color: mean\n",
            "    mask_ratio: 0.6\n",
            "  focal_gamma: 1.0\n",
            "  in_chans: 2\n",
            "  input_size:\n",
            "  - 192\n",
            "  - 192\n",
            "  loss_weight: 1.0\n",
            "  n_queries: 256\n",
            "  online_temp: 0.1\n",
            "  reduction: none\n",
            "  residual: false\n",
            "  unmask_weight: 0.0\n",
            "  warmup_branch_temp: 0.04\n",
            "  warmup_branch_temp_epochs: 2\n",
            "schedule:\n",
            "  decay_epochs: 30\n",
            "  decay_rate: 0.1\n",
            "  gamma: 0.1\n",
            "  min_lr: 2.0e-05\n",
            "  multisteps: []\n",
            "  name: cosine\n",
            "  warmup_epochs: 100\n",
            "  warmup_factor: 0.01\n",
            "  warmup_method: linear\n",
            "seed: 322\n",
            "stage: 0\n",
            "text:\n",
            "  bos_token_id: 1\n",
            "  eos_token_id: 2\n",
            "  hidden_act: silu\n",
            "  hidden_size: 4096\n",
            "  initializer_range: 0.02\n",
            "  intermediate_size: 11008\n",
            "  max_position_embeddings: 2048\n",
            "  num_attention_heads: 32\n",
            "  num_hidden_layers: 32\n",
            "  pad_token_id: 0\n",
            "  path: meta-llama/Llama-2-7b-chat-hf\n",
            "  rms_norm_eps: 1e-5\n",
            "  tie_word_embeddings: false\n",
            "  use_cache: true\n",
            "  vocab_size: 32000\n",
            "transform:\n",
            "  input_size:\n",
            "  - 224\n",
            "  - 224\n",
            "  rand_aug: rand-m5-n2-mstd0.5-inc1\n",
            "tune_im_patch: false\n",
            "tune_im_start: false\n",
            "tune_rgb_bk: false\n",
            "tune_rgb_pooler: false\n",
            "use_checkpoint: false\n",
            "wandb: false\n",
            "wd: 0.0\n",
            "workers: 4\n",
            "world_size: 1\n",
            "\n",
            "\u001b[32m[04/18 22:30:23 train]: \u001b[0mFull config saved to /content/drive/MyDrive/lhrsbot/output/AID_results/Size_50/config.json\n",
            "\u001b[32m[04/18 22:30:23 train]: \u001b[0maccelerator: gpu\n",
            "adjust_norm: false\n",
            "alignment_dim: 768\n",
            "batch_size: 8\n",
            "bf16: true\n",
            "bits: 16\n",
            "config: null\n",
            "data_path: /content/drive/MyDrive/Datasets/AID_resolution/Size_50/\n",
            "double_quant: true\n",
            "dtype: float16\n",
            "enable_amp: true\n",
            "entity: pumpkinn\n",
            "epochs: 2\n",
            "eval:\n",
            "  dataset: AID\n",
            "fp16: false\n",
            "generate: false\n",
            "gpus: 0\n",
            "inf_sampler: false\n",
            "is_distribute: false\n",
            "local_rank: 0\n",
            "lora:\n",
            "  enable: false\n",
            "  lora_alpha: 256\n",
            "  lora_bias: none\n",
            "  lora_dropout: 0.05\n",
            "  lora_r: 128\n",
            "lr: 0.0002\n",
            "max_grad_norm: 0.3\n",
            "model_path: /content/drive/MyDrive/lhrsbot/Stage3/FINAL.pt\n",
            "optimizer: adanp\n",
            "opts: null\n",
            "output: /content/drive/MyDrive/lhrsbot/output/AID_results/Size_50/\n",
            "project: MaskIndexNet\n",
            "prompt_template: llava_llama_2\n",
            "quant_type: nf4\n",
            "rank: 0\n",
            "rgb_vision:\n",
            "  arch: vit_large\n",
            "  attn_pooler:\n",
            "    num_attn_heads: 16\n",
            "    num_layers: 6\n",
            "    num_query: 144\n",
            "  input_patchnorm: false\n",
            "  input_size:\n",
            "  - 224\n",
            "  - 224\n",
            "  patch_dropout: 0.0\n",
            "  tune_pooler: true\n",
            "  vit_name: openai/clip-vit-large-patch14\n",
            "sar_vision:\n",
            "  activate: sigmoid\n",
            "  alpha: 0.2\n",
            "  arch: base\n",
            "  branch_temp: 0.07\n",
            "  decoder:\n",
            "    heads: 12\n",
            "    hidden_size: 768\n",
            "    layers: 12\n",
            "    mask_color: mean\n",
            "    mask_ratio: 0.6\n",
            "  focal_gamma: 1.0\n",
            "  in_chans: 2\n",
            "  input_size:\n",
            "  - 192\n",
            "  - 192\n",
            "  loss_weight: 1.0\n",
            "  n_queries: 256\n",
            "  online_temp: 0.1\n",
            "  reduction: none\n",
            "  residual: false\n",
            "  unmask_weight: 0.0\n",
            "  warmup_branch_temp: 0.04\n",
            "  warmup_branch_temp_epochs: 2\n",
            "schedule:\n",
            "  decay_epochs: 30\n",
            "  decay_rate: 0.1\n",
            "  gamma: 0.1\n",
            "  min_lr: 2.0e-05\n",
            "  multisteps: []\n",
            "  name: cosine\n",
            "  warmup_epochs: 100\n",
            "  warmup_factor: 0.01\n",
            "  warmup_method: linear\n",
            "seed: 322\n",
            "stage: 0\n",
            "text:\n",
            "  bos_token_id: 1\n",
            "  eos_token_id: 2\n",
            "  hidden_act: silu\n",
            "  hidden_size: 4096\n",
            "  initializer_range: 0.02\n",
            "  intermediate_size: 11008\n",
            "  max_position_embeddings: 2048\n",
            "  num_attention_heads: 32\n",
            "  num_hidden_layers: 32\n",
            "  pad_token_id: 0\n",
            "  path: meta-llama/Llama-2-7b-chat-hf\n",
            "  rms_norm_eps: 1e-5\n",
            "  tie_word_embeddings: false\n",
            "  use_cache: true\n",
            "  vocab_size: 32000\n",
            "transform:\n",
            "  input_size:\n",
            "  - 224\n",
            "  - 224\n",
            "  rand_aug: rand-m5-n2-mstd0.5-inc1\n",
            "tune_im_patch: false\n",
            "tune_im_start: false\n",
            "tune_rgb_bk: false\n",
            "tune_rgb_pooler: false\n",
            "use_checkpoint: false\n",
            "wandb: false\n",
            "wd: 0.0\n",
            "workers: 4\n",
            "world_size: 1\n",
            "\n",
            "\u001b[32m[04/18 22:30:23 train]: \u001b[0mCreating model\n",
            "config.json: 100% 4.52k/4.52k [00:00<00:00, 18.2MB/s]\n",
            "model.safetensors: 100% 1.71G/1.71G [00:03<00:00, 437MB/s]\n",
            "config.json: 100% 614/614 [00:00<00:00, 3.53MB/s]\n",
            "model.safetensors.index.json: 100% 26.8k/26.8k [00:00<00:00, 83.7MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/9.98G [00:00<00:22, 434MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 105M/9.98G [00:00<00:21, 460MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 157M/9.98G [00:00<00:21, 458MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 210M/9.98G [00:00<00:21, 461MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 262M/9.98G [00:00<00:20, 470MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 315M/9.98G [00:00<00:20, 472MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 367M/9.98G [00:00<00:20, 471MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 419M/9.98G [00:00<00:20, 468MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 472M/9.98G [00:01<00:20, 455MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 524M/9.98G [00:01<00:20, 455MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 577M/9.98G [00:01<00:20, 460MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 629M/9.98G [00:01<00:20, 454MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 682M/9.98G [00:01<00:20, 459MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 734M/9.98G [00:01<00:19, 464MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 786M/9.98G [00:01<00:20, 459MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 839M/9.98G [00:01<00:20, 439MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 891M/9.98G [00:01<00:20, 435MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 944M/9.98G [00:02<00:20, 438MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 996M/9.98G [00:02<00:20, 442MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.05G/9.98G [00:02<00:19, 459MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 1.10G/9.98G [00:02<00:20, 440MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.15G/9.98G [00:02<00:19, 445MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 1.21G/9.98G [00:02<00:19, 454MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.26G/9.98G [00:02<00:19, 450MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 1.31G/9.98G [00:02<00:18, 459MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.36G/9.98G [00:02<00:18, 475MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 1.43G/9.98G [00:03<00:17, 493MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.48G/9.98G [00:03<00:18, 466MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 1.53G/9.98G [00:03<00:17, 475MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 1.59G/9.98G [00:03<00:17, 493MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.66G/9.98G [00:03<00:16, 512MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 1.72G/9.98G [00:03<00:15, 521MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.78G/9.98G [00:03<00:15, 526MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 1.85G/9.98G [00:03<00:15, 531MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 1.91G/9.98G [00:04<00:15, 534MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 1.97G/9.98G [00:04<00:14, 534MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 2.03G/9.98G [00:04<00:15, 522MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 2.09G/9.98G [00:04<00:23, 337MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.15G/9.98G [00:04<00:20, 379MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 2.20G/9.98G [00:04<00:19, 399MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.25G/9.98G [00:04<00:18, 427MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 2.31G/9.98G [00:05<00:25, 299MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.36G/9.98G [00:05<00:22, 341MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 2.42G/9.98G [00:05<00:19, 396MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 2.49G/9.98G [00:05<00:16, 441MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.55G/9.98G [00:05<00:15, 477MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 2.61G/9.98G [00:05<00:18, 388MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.66G/9.98G [00:06<00:24, 298MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 2.71G/9.98G [00:06<00:27, 263MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.75G/9.98G [00:06<00:30, 237MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.78G/9.98G [00:06<00:31, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.81G/9.98G [00:06<00:31, 231MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 2.84G/9.98G [00:07<00:29, 240MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.87G/9.98G [00:07<00:27, 255MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 2.90G/9.98G [00:07<00:26, 268MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.95G/9.98G [00:07<00:23, 294MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 2.99G/9.98G [00:07<00:21, 322MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 3.03G/9.98G [00:07<00:21, 327MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.07G/9.98G [00:07<00:20, 343MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 3.11G/9.98G [00:07<00:20, 341MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.16G/9.98G [00:07<00:21, 311MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.20G/9.98G [00:08<00:21, 320MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 3.24G/9.98G [00:08<00:20, 330MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.28G/9.98G [00:08<00:19, 347MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 3.33G/9.98G [00:08<00:17, 384MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.39G/9.98G [00:08<00:15, 413MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 3.44G/9.98G [00:08<00:15, 429MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 3.49G/9.98G [00:08<00:14, 437MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.54G/9.98G [00:08<00:14, 444MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 3.60G/9.98G [00:08<00:14, 445MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.65G/9.98G [00:09<00:14, 428MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 3.70G/9.98G [00:09<00:14, 432MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.75G/9.98G [00:09<00:14, 433MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 3.81G/9.98G [00:09<00:14, 437MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.86G/9.98G [00:09<00:13, 437MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 3.91G/9.98G [00:09<00:14, 430MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 3.96G/9.98G [00:09<00:13, 430MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 4.02G/9.98G [00:09<00:13, 436MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.07G/9.98G [00:10<00:13, 446MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 4.12G/9.98G [00:10<00:12, 457MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.17G/9.98G [00:10<00:12, 455MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 4.23G/9.98G [00:10<00:12, 462MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.28G/9.98G [00:10<00:12, 465MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 4.33G/9.98G [00:10<00:12, 464MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 4.38G/9.98G [00:10<00:11, 470MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.45G/9.98G [00:10<00:11, 486MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 4.50G/9.98G [00:10<00:11, 496MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.55G/9.98G [00:11<00:14, 386MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 4.60G/9.98G [00:11<00:15, 351MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.65G/9.98G [00:11<00:16, 328MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.69G/9.98G [00:11<00:16, 318MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 4.73G/9.98G [00:11<00:16, 314MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.77G/9.98G [00:11<00:17, 298MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 4.80G/9.98G [00:12<00:18, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.85G/9.98G [00:12<00:16, 312MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.90G/9.98G [00:12<00:16, 302MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 4.93G/9.98G [00:12<00:17, 295MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.96G/9.98G [00:12<00:17, 287MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 4.99G/9.98G [00:12<00:17, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 5.02G/9.98G [00:12<00:18, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.05G/9.98G [00:12<00:18, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.09G/9.98G [00:13<00:17, 280MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 5.12G/9.98G [00:13<00:17, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.15G/9.98G [00:13<00:17, 278MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.19G/9.98G [00:13<00:16, 291MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 5.22G/9.98G [00:13<00:16, 293MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.26G/9.98G [00:13<00:15, 308MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 5.31G/9.98G [00:13<00:13, 336MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.36G/9.98G [00:13<00:12, 371MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 5.41G/9.98G [00:13<00:11, 394MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.46G/9.98G [00:14<00:10, 414MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 5.52G/9.98G [00:14<00:10, 428MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.57G/9.98G [00:14<00:10, 413MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 5.61G/9.98G [00:14<00:10, 414MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.65G/9.98G [00:14<00:10, 415MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 5.70G/9.98G [00:14<00:10, 418MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.75G/9.98G [00:14<00:10, 413MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 5.80G/9.98G [00:14<00:09, 422MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.85G/9.98G [00:15<00:09, 432MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 5.90G/9.98G [00:15<00:09, 439MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 5.96G/9.98G [00:15<00:09, 440MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 6.01G/9.98G [00:15<00:08, 441MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.06G/9.98G [00:15<00:08, 448MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 6.11G/9.98G [00:15<00:08, 452MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.17G/9.98G [00:15<00:08, 451MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 6.22G/9.98G [00:15<00:08, 447MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.27G/9.98G [00:15<00:08, 443MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 6.32G/9.98G [00:16<00:08, 431MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.38G/9.98G [00:16<00:08, 428MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 6.43G/9.98G [00:16<00:08, 438MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.48G/9.98G [00:16<00:07, 447MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 6.53G/9.98G [00:16<00:07, 449MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 6.59G/9.98G [00:16<00:07, 449MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.64G/9.98G [00:16<00:07, 452MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 6.69G/9.98G [00:16<00:07, 453MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.74G/9.98G [00:17<00:07, 442MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 6.79G/9.98G [00:17<00:07, 428MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.85G/9.98G [00:17<00:07, 409MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.89G/9.98G [00:17<00:08, 386MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 6.93G/9.98G [00:17<00:07, 385MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 6.97G/9.98G [00:17<00:07, 393MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 7.01G/9.98G [00:17<00:07, 389MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.06G/9.98G [00:17<00:07, 382MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 7.10G/9.98G [00:17<00:07, 387MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.14G/9.98G [00:18<00:07, 384MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.18G/9.98G [00:18<00:07, 377MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 7.22G/9.98G [00:18<00:07, 369MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.27G/9.98G [00:18<00:07, 357MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 7.31G/9.98G [00:18<00:07, 344MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.35G/9.98G [00:18<00:07, 338MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 7.39G/9.98G [00:18<00:07, 326MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.43G/9.98G [00:18<00:08, 315MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.48G/9.98G [00:19<00:08, 301MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 7.51G/9.98G [00:19<00:08, 303MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.54G/9.98G [00:19<00:08, 303MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.58G/9.98G [00:19<00:07, 311MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 7.61G/9.98G [00:19<00:07, 307MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.64G/9.98G [00:19<00:07, 305MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.68G/9.98G [00:19<00:07, 307MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 7.71G/9.98G [00:19<00:07, 301MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.74G/9.98G [00:19<00:07, 296MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.77G/9.98G [00:20<00:07, 289MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 7.80G/9.98G [00:20<00:07, 287MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.83G/9.98G [00:20<00:07, 279MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.86G/9.98G [00:20<00:07, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.90G/9.98G [00:20<00:07, 264MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 7.93G/9.98G [00:20<00:07, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.96G/9.98G [00:20<00:07, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 7.99G/9.98G [00:20<00:07, 269MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 8.02G/9.98G [00:21<00:07, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.06G/9.98G [00:21<00:06, 281MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 8.11G/9.98G [00:21<00:06, 310MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.15G/9.98G [00:21<00:05, 323MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 8.19G/9.98G [00:21<00:05, 345MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.24G/9.98G [00:21<00:04, 381MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 8.29G/9.98G [00:21<00:04, 411MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.35G/9.98G [00:21<00:03, 424MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 8.40G/9.98G [00:21<00:03, 437MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.45G/9.98G [00:22<00:05, 271MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 8.51G/9.98G [00:22<00:04, 330MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 8.58G/9.98G [00:22<00:03, 387MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.64G/9.98G [00:22<00:03, 426MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 8.70G/9.98G [00:22<00:02, 458MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.77G/9.98G [00:22<00:02, 481MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 8.83G/9.98G [00:22<00:02, 502MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 8.89G/9.98G [00:23<00:02, 521MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 8.95G/9.98G [00:23<00:01, 535MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 9.02G/9.98G [00:23<00:01, 550MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 9.08G/9.98G [00:23<00:01, 560MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.14G/9.98G [00:23<00:02, 354MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 9.20G/9.98G [00:24<00:02, 295MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.24G/9.98G [00:24<00:02, 260MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.28G/9.98G [00:24<00:02, 244MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 9.31G/9.98G [00:24<00:02, 251MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.35G/9.98G [00:24<00:02, 270MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 9.40G/9.98G [00:24<00:01, 299MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.44G/9.98G [00:24<00:01, 315MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 9.48G/9.98G [00:25<00:01, 338MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.53G/9.98G [00:25<00:01, 367MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 9.58G/9.98G [00:25<00:01, 391MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.64G/9.98G [00:25<00:00, 406MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 9.69G/9.98G [00:25<00:00, 418MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.74G/9.98G [00:25<00:00, 423MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 9.79G/9.98G [00:25<00:00, 419MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.85G/9.98G [00:25<00:00, 421MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 9.90G/9.98G [00:25<00:00, 425MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 9.98G/9.98G [00:26<00:00, 381MB/s]\n",
            "Downloading shards:  50% 1/2 [00:26<00:26, 26.52s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 52.4M/3.50G [00:00<00:07, 488MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   3% 105M/3.50G [00:00<00:06, 485MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:   4% 157M/3.50G [00:00<00:06, 487MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   6% 210M/3.50G [00:00<00:06, 493MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 262M/3.50G [00:00<00:06, 496MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 315M/3.50G [00:00<00:06, 504MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  10% 367M/3.50G [00:00<00:06, 507MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  12% 419M/3.50G [00:00<00:06, 509MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  13% 472M/3.50G [00:00<00:06, 475MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 524M/3.50G [00:01<00:07, 413MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  16% 577M/3.50G [00:01<00:07, 377MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  18% 619M/3.50G [00:01<00:07, 363MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  19% 661M/3.50G [00:01<00:08, 346MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 703M/3.50G [00:01<00:08, 341MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  21% 744M/3.50G [00:01<00:08, 336MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  22% 786M/3.50G [00:01<00:08, 327MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 828M/3.50G [00:02<00:08, 312MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  25% 870M/3.50G [00:02<00:08, 310MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  26% 902M/3.50G [00:02<00:08, 308MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  27% 944M/3.50G [00:02<00:08, 317MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  28% 986M/3.50G [00:02<00:07, 315MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 1.03G/3.50G [00:06<01:24, 29.4MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  31% 1.07G/3.50G [00:07<00:59, 40.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  32% 1.11G/3.50G [00:07<00:43, 55.3MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  33% 1.15G/3.50G [00:07<00:31, 74.5MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 1.20G/3.50G [00:07<00:23, 96.9MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  35% 1.23G/3.50G [00:07<00:19, 116MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  36% 1.26G/3.50G [00:07<00:16, 135MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  37% 1.29G/3.50G [00:07<00:13, 158MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  38% 1.32G/3.50G [00:07<00:12, 181MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 1.36G/3.50G [00:08<00:10, 212MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  40% 1.39G/3.50G [00:08<00:09, 228MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  41% 1.43G/3.50G [00:08<00:08, 239MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  42% 1.46G/3.50G [00:08<00:08, 248MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.49G/3.50G [00:08<00:08, 249MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.52G/3.50G [00:08<00:08, 237MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 1.55G/3.50G [00:08<00:08, 227MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  45% 1.58G/3.50G [00:08<00:08, 219MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  46% 1.61G/3.50G [00:09<00:09, 208MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  47% 1.65G/3.50G [00:09<00:08, 222MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  48% 1.69G/3.50G [00:09<00:07, 252MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 1.73G/3.50G [00:09<00:06, 285MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  50% 1.76G/3.50G [00:09<00:06, 280MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  51% 1.79G/3.50G [00:09<00:06, 275MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  52% 1.84G/3.50G [00:09<00:05, 286MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 1.88G/3.50G [00:09<00:05, 305MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  55% 1.93G/3.50G [00:10<00:04, 344MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  57% 1.98G/3.50G [00:10<00:03, 386MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  58% 2.02G/3.50G [00:10<00:04, 349MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 2.08G/3.50G [00:10<00:03, 375MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  61% 2.12G/3.50G [00:10<00:03, 363MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  62% 2.16G/3.50G [00:10<00:03, 355MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 2.20G/3.50G [00:10<00:03, 336MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  64% 2.24G/3.50G [00:10<00:03, 325MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  65% 2.29G/3.50G [00:11<00:03, 312MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.33G/3.50G [00:11<00:03, 310MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  67% 2.36G/3.50G [00:11<00:03, 302MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.40G/3.50G [00:11<00:03, 302MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  69% 2.43G/3.50G [00:11<00:03, 298MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 2.46G/3.50G [00:11<00:03, 291MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  71% 2.50G/3.50G [00:11<00:03, 274MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  72% 2.53G/3.50G [00:12<00:03, 260MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 2.56G/3.50G [00:12<00:03, 247MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  74% 2.59G/3.50G [00:12<00:03, 233MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  75% 2.62G/3.50G [00:12<00:03, 232MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  76% 2.65G/3.50G [00:12<00:03, 236MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  77% 2.68G/3.50G [00:12<00:03, 243MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.73G/3.50G [00:12<00:02, 275MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  79% 2.76G/3.50G [00:12<00:02, 278MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  80% 2.81G/3.50G [00:13<00:02, 327MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  81% 2.85G/3.50G [00:13<00:01, 341MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.90G/3.50G [00:13<00:01, 386MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  84% 2.96G/3.50G [00:13<00:01, 417MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  86% 3.01G/3.50G [00:13<00:01, 442MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  87% 3.06G/3.50G [00:13<00:00, 453MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  89% 3.12G/3.50G [00:13<00:00, 476MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  91% 3.18G/3.50G [00:13<00:00, 488MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  92% 3.23G/3.50G [00:13<00:00, 497MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  94% 3.28G/3.50G [00:14<00:00, 487MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  95% 3.33G/3.50G [00:14<00:00, 493MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 3.39G/3.50G [00:14<00:00, 492MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  98% 3.44G/3.50G [00:14<00:00, 489MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 3.50G/3.50G [00:14<00:00, 242MB/s]\n",
            "Downloading shards: 100% 2/2 [00:41<00:00, 20.66s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:05<00:00,  2.53s/it]\n",
            "generation_config.json: 100% 188/188 [00:00<00:00, 931kB/s]\n",
            "tokenizer_config.json: 100% 1.62k/1.62k [00:00<00:00, 9.52MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 389MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 2.57MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 1.91MB/s]\n",
            "\u001b[32m[04/18 22:31:51 train]: \u001b[0mBuild dataloader: Epoch length = 376\n",
            "\u001b[32m[04/18 22:31:51 train]: \u001b[0mLoading pretrained checkpoint from /content/drive/MyDrive/lhrsbot/Stage3/FINAL.pt\n",
            "\u001b[32m[04/18 22:32:18 train]: \u001b[0mLoading RGB encoder.\n",
            "\u001b[32m[04/18 22:32:18 train]: \u001b[0mAfter loading RGB encoder: Missing: []. Unexpected: []\n",
            "\u001b[32m[04/18 22:32:18 train]: \u001b[0mLoadding LoRA parameters.\n",
            "Evaluating:   0% 0/3008 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Evaluating:   0% 0/3008 [00:14<?, ?it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/lhrsbot/main_cls.py\", line 249, in <module>\n",
            "    main(config)\n",
            "  File \"/content/drive/MyDrive/lhrsbot/main_cls.py\", line 196, in main\n",
            "    output_ids = model.generate(\n",
            "  File \"/content/drive/MyDrive/lhrsbot/lhrs/models/UniBind.py\", line 232, in generate\n",
            "    return self.text.generate(\n",
            "  File \"/content/drive/MyDrive/lhrsbot/lhrs/models/text_modal.py\", line 600, in generate\n",
            "    outputs = self.text_encoder.generate(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 1544, in generate\n",
            "    return self.greedy_search(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py\", line 2404, in greedy_search\n",
            "    outputs = self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 1176, in forward\n",
            "    outputs = self.model(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 1019, in forward\n",
            "    layer_outputs = decoder_layer(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 755, in forward\n",
            "    hidden_states = self.mlp(hidden_states)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py\", line 241, in forward\n",
            "    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 58.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 5.06 MiB is free. Process 38244 has 14.74 GiB memory in use. Of the allocated memory 14.31 GiB is allocated by PyTorch, and 300.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESIC:"
      ],
      "metadata": {
        "id": "3WiZ6onD2w3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main_cls.py -c /content/drive/MyDrive/lhrsbot/Config/multi_modal_eval.yaml --model-path /content/drive/MyDrive/lhrsbot/Stage3/FINAL.pt --data-path /content/drive/MyDrive/Datasets/Train_Test_Splits_RESISC45/test/ --accelerator \"gpu\" --workers 4 --enable-amp True --output /content/drive/MyDrive/lhrsbot/output/RESISC_results --batch-size 8"
      ],
      "metadata": {
        "id": "j5jKP3WSDKw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dfcd293-0fa3-4609-918d-98c7b59079bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2024-04-10 16:35:22,500] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "2024-04-10 16:35:25.725267: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-04-10 16:35:25.725320: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-04-10 16:35:25.727291: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-04-10 16:35:27.036659: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Not using distributed mode.\n",
            "accelerator: gpu\n",
            "adjust_norm: false\n",
            "alignment_dim: 768\n",
            "batch_size: 8\n",
            "bf16: true\n",
            "bits: 16\n",
            "config: null\n",
            "data_path: /content/drive/MyDrive/Datasets/Train_Test_Splits_RESISC45/test/\n",
            "double_quant: true\n",
            "dtype: float16\n",
            "enable_amp: true\n",
            "entity: pumpkinn\n",
            "epochs: 2\n",
            "eval:\n",
            "  dataset: AID\n",
            "fp16: false\n",
            "generate: false\n",
            "gpus: 0\n",
            "inf_sampler: false\n",
            "is_distribute: false\n",
            "local_rank: 0\n",
            "lora:\n",
            "  enable: false\n",
            "  lora_alpha: 256\n",
            "  lora_bias: none\n",
            "  lora_dropout: 0.05\n",
            "  lora_r: 128\n",
            "lr: 0.0002\n",
            "max_grad_norm: 0.3\n",
            "model_path: /content/drive/MyDrive/lhrsbot/Stage3/FINAL.pt\n",
            "optimizer: adanp\n",
            "opts: null\n",
            "output: /content/drive/MyDrive/lhrsbot/output/RESISC_results\n",
            "project: MaskIndexNet\n",
            "prompt_template: llava_llama_2\n",
            "quant_type: nf4\n",
            "rank: 0\n",
            "rgb_vision:\n",
            "  arch: vit_large\n",
            "  attn_pooler:\n",
            "    num_attn_heads: 16\n",
            "    num_layers: 6\n",
            "    num_query: 144\n",
            "  input_patchnorm: false\n",
            "  input_size:\n",
            "  - 224\n",
            "  - 224\n",
            "  patch_dropout: 0.0\n",
            "  tune_pooler: true\n",
            "  vit_name: openai/clip-vit-large-patch14\n",
            "sar_vision:\n",
            "  activate: sigmoid\n",
            "  alpha: 0.2\n",
            "  arch: base\n",
            "  branch_temp: 0.07\n",
            "  decoder:\n",
            "    heads: 12\n",
            "    hidden_size: 768\n",
            "    layers: 12\n",
            "    mask_color: mean\n",
            "    mask_ratio: 0.6\n",
            "  focal_gamma: 1.0\n",
            "  in_chans: 2\n",
            "  input_size:\n",
            "  - 192\n",
            "  - 192\n",
            "  loss_weight: 1.0\n",
            "  n_queries: 256\n",
            "  online_temp: 0.1\n",
            "  reduction: none\n",
            "  residual: false\n",
            "  unmask_weight: 0.0\n",
            "  warmup_branch_temp: 0.04\n",
            "  warmup_branch_temp_epochs: 2\n",
            "schedule:\n",
            "  decay_epochs: 30\n",
            "  decay_rate: 0.1\n",
            "  gamma: 0.1\n",
            "  min_lr: 2.0e-05\n",
            "  multisteps: []\n",
            "  name: cosine\n",
            "  warmup_epochs: 100\n",
            "  warmup_factor: 0.01\n",
            "  warmup_method: linear\n",
            "seed: 322\n",
            "stage: 0\n",
            "text:\n",
            "  bos_token_id: 1\n",
            "  eos_token_id: 2\n",
            "  hidden_act: silu\n",
            "  hidden_size: 4096\n",
            "  initializer_range: 0.02\n",
            "  intermediate_size: 11008\n",
            "  max_position_embeddings: 2048\n",
            "  num_attention_heads: 32\n",
            "  num_hidden_layers: 32\n",
            "  pad_token_id: 0\n",
            "  path: meta-llama/Llama-2-7b-chat-hf\n",
            "  rms_norm_eps: 1e-5\n",
            "  tie_word_embeddings: false\n",
            "  use_cache: true\n",
            "  vocab_size: 32000\n",
            "transform:\n",
            "  input_size:\n",
            "  - 224\n",
            "  - 224\n",
            "  rand_aug: rand-m5-n2-mstd0.5-inc1\n",
            "tune_im_patch: false\n",
            "tune_im_start: false\n",
            "tune_rgb_bk: false\n",
            "tune_rgb_pooler: false\n",
            "use_checkpoint: false\n",
            "wandb: false\n",
            "wd: 0.0\n",
            "workers: 4\n",
            "world_size: 1\n",
            "\n",
            "\u001b[32m[04/10 16:35:28 train]: \u001b[0mFull config saved to /content/drive/MyDrive/lhrsbot/output/RESISC_results/config.json\n",
            "\u001b[32m[04/10 16:35:28 train]: \u001b[0maccelerator: gpu\n",
            "adjust_norm: false\n",
            "alignment_dim: 768\n",
            "batch_size: 8\n",
            "bf16: true\n",
            "bits: 16\n",
            "config: null\n",
            "data_path: /content/drive/MyDrive/Datasets/Train_Test_Splits_RESISC45/test/\n",
            "double_quant: true\n",
            "dtype: float16\n",
            "enable_amp: true\n",
            "entity: pumpkinn\n",
            "epochs: 2\n",
            "eval:\n",
            "  dataset: AID\n",
            "fp16: false\n",
            "generate: false\n",
            "gpus: 0\n",
            "inf_sampler: false\n",
            "is_distribute: false\n",
            "local_rank: 0\n",
            "lora:\n",
            "  enable: false\n",
            "  lora_alpha: 256\n",
            "  lora_bias: none\n",
            "  lora_dropout: 0.05\n",
            "  lora_r: 128\n",
            "lr: 0.0002\n",
            "max_grad_norm: 0.3\n",
            "model_path: /content/drive/MyDrive/lhrsbot/Stage3/FINAL.pt\n",
            "optimizer: adanp\n",
            "opts: null\n",
            "output: /content/drive/MyDrive/lhrsbot/output/RESISC_results\n",
            "project: MaskIndexNet\n",
            "prompt_template: llava_llama_2\n",
            "quant_type: nf4\n",
            "rank: 0\n",
            "rgb_vision:\n",
            "  arch: vit_large\n",
            "  attn_pooler:\n",
            "    num_attn_heads: 16\n",
            "    num_layers: 6\n",
            "    num_query: 144\n",
            "  input_patchnorm: false\n",
            "  input_size:\n",
            "  - 224\n",
            "  - 224\n",
            "  patch_dropout: 0.0\n",
            "  tune_pooler: true\n",
            "  vit_name: openai/clip-vit-large-patch14\n",
            "sar_vision:\n",
            "  activate: sigmoid\n",
            "  alpha: 0.2\n",
            "  arch: base\n",
            "  branch_temp: 0.07\n",
            "  decoder:\n",
            "    heads: 12\n",
            "    hidden_size: 768\n",
            "    layers: 12\n",
            "    mask_color: mean\n",
            "    mask_ratio: 0.6\n",
            "  focal_gamma: 1.0\n",
            "  in_chans: 2\n",
            "  input_size:\n",
            "  - 192\n",
            "  - 192\n",
            "  loss_weight: 1.0\n",
            "  n_queries: 256\n",
            "  online_temp: 0.1\n",
            "  reduction: none\n",
            "  residual: false\n",
            "  unmask_weight: 0.0\n",
            "  warmup_branch_temp: 0.04\n",
            "  warmup_branch_temp_epochs: 2\n",
            "schedule:\n",
            "  decay_epochs: 30\n",
            "  decay_rate: 0.1\n",
            "  gamma: 0.1\n",
            "  min_lr: 2.0e-05\n",
            "  multisteps: []\n",
            "  name: cosine\n",
            "  warmup_epochs: 100\n",
            "  warmup_factor: 0.01\n",
            "  warmup_method: linear\n",
            "seed: 322\n",
            "stage: 0\n",
            "text:\n",
            "  bos_token_id: 1\n",
            "  eos_token_id: 2\n",
            "  hidden_act: silu\n",
            "  hidden_size: 4096\n",
            "  initializer_range: 0.02\n",
            "  intermediate_size: 11008\n",
            "  max_position_embeddings: 2048\n",
            "  num_attention_heads: 32\n",
            "  num_hidden_layers: 32\n",
            "  pad_token_id: 0\n",
            "  path: meta-llama/Llama-2-7b-chat-hf\n",
            "  rms_norm_eps: 1e-5\n",
            "  tie_word_embeddings: false\n",
            "  use_cache: true\n",
            "  vocab_size: 32000\n",
            "transform:\n",
            "  input_size:\n",
            "  - 224\n",
            "  - 224\n",
            "  rand_aug: rand-m5-n2-mstd0.5-inc1\n",
            "tune_im_patch: false\n",
            "tune_im_start: false\n",
            "tune_rgb_bk: false\n",
            "tune_rgb_pooler: false\n",
            "use_checkpoint: false\n",
            "wandb: false\n",
            "wd: 0.0\n",
            "workers: 4\n",
            "world_size: 1\n",
            "\n",
            "\u001b[32m[04/10 16:35:28 train]: \u001b[0mCreating model\n",
            "Loading checkpoint shards: 100% 2/2 [00:05<00:00,  2.78s/it]\n",
            "\u001b[32m[04/10 16:35:53 train]: \u001b[0mBuild dataloader: Epoch length = 487\n",
            "\u001b[32m[04/10 16:35:53 train]: \u001b[0mLoading pretrained checkpoint from /content/drive/MyDrive/lhrsbot/Stage3/FINAL.pt\n",
            "\u001b[32m[04/10 16:35:54 train]: \u001b[0mLoading RGB encoder.\n",
            "\u001b[32m[04/10 16:35:55 train]: \u001b[0mAfter loading RGB encoder: Missing: []. Unexpected: []\n",
            "\u001b[32m[04/10 16:35:55 train]: \u001b[0mLoadding LoRA parameters.\n",
            "Evaluating:   0% 0/3896 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "Evaluating: 100% 3896/3896 [15:43<00:00,  4.13it/s]\n",
            "\u001b[32m[04/10 16:51:43 train]: \u001b[0m                    precision    recall  f1-score   support\n",
            "\n",
            "          airplane      0.897     0.991     0.941       211\n",
            "           airport      1.000     0.863     0.926       211\n",
            "  baseball diamond      0.949     0.976     0.963       211\n",
            "  basketball court      0.995     0.986     0.990       211\n",
            "             beach      0.959     0.991     0.974       211\n",
            "            bridge      0.995     0.986     0.990       211\n",
            "         chaparral      0.963     1.000     0.981       211\n",
            "            church      0.884     0.834     0.859       211\n",
            " circular farmland      0.995     0.957     0.976       211\n",
            "             cloud      0.995     0.986     0.990       211\n",
            "   commercial area      0.962     0.839     0.896       211\n",
            " dense residential      0.933     0.858     0.894       211\n",
            "            desert      0.990     0.934     0.961       211\n",
            "            forest      0.990     0.967     0.978       211\n",
            "           freeway      0.929     0.863     0.894       211\n",
            "       golf course      0.972     0.981     0.976       211\n",
            "ground track field      0.985     0.924     0.954       211\n",
            "            harbor      0.986     0.991     0.988       211\n",
            "            island      0.615     1.000     0.762         8\n",
            "  mobile home park      0.353     1.000     0.522        12\n",
            "          overpass      0.292     1.000     0.452         7\n",
            "            palace      0.067     0.750     0.122         4\n",
            "       parking lot      0.600     1.000     0.750         6\n",
            "           railway      0.400     1.000     0.571         2\n",
            "        roundabout      0.881     0.974     0.925        38\n",
            "           sea ice      1.000     1.000     1.000         9\n",
            "          snowberg      0.818     1.000     0.900         9\n",
            "\n",
            "          accuracy                          0.941      3893\n",
            "         macro avg      0.830     0.950     0.857      3893\n",
            "      weighted avg      0.959     0.941     0.948      3893\n",
            "\n",
            "\u001b[32m[04/10 16:51:43 train]: \u001b[0m0.9499205491348169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ELY2Cj34DKt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XXeYoApLDKjS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}